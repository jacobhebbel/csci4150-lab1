{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T15:17:52.522077Z",
     "start_time": "2026-01-29T15:17:49.226409Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "adult = fetch_ucirepo(id=2)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = adult.data.features\n",
    "y = adult.data.targets\n",
    "\n",
    "# metadata\n",
    "print(adult.metadata)\n",
    "\n",
    "# variable information\n",
    "print(adult.variables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9935c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries. Run this first!!\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013fbcf",
   "metadata": {},
   "source": [
    "## Dataset Analysis\n",
    "\n",
    "### About\n",
    "We chose the [Adult 2 dataset](https://archive.ics.uci.edu/dataset/2/adult) from UCI's Machine Learning Repository. This dataset compiles US Census information relevant to predicting income. It will be used to predict if a sample has an income over 50k USD a year.\n",
    "\n",
    "### Does it comply with the requirements?\n",
    "Adult 2 contains 48,000 rows, so it has over 2,000 rows. It contains 14 features, however some will not be used. We will still consider at least 10. Finally, there are several opportunities for encountering data leakage. \n",
    "\n",
    "First, a feature *fnl_wgt* computes how many rows in the dataset are like this. Frequency of a specific sample considers every sample in the set, which means this feature is not individual to the sample. Therefore, we will not consider this column during training.\n",
    "\n",
    "Second, there are several duplicate entries in the dataset. We must make each sample singular to give each sample equal weighting. \n",
    "\n",
    "Finally, there are two columns pertaining to education: a string representation and an enumeration of the string options. Both should not be used, as it may give that feature unequal weighting, and samples with unknown education backgrounds would be minimized.\n",
    "\n",
    "Therefore, this dataset is compliant with the project outlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459f0731634b658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block will drop some columns\n",
    "\n",
    "print('columns before dropping:\\n', X.columns)\n",
    "\n",
    "dropped_columns = [\n",
    "    'fnlwgt',\n",
    "    'education-num'\n",
    "]\n",
    "\n",
    "new_data = X.drop(columns=dropped_columns)\n",
    "\n",
    "print('columns after dropping\\n', new_data.columns)\n",
    "\n",
    "# now new_data has all the right variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a5e92e",
   "metadata": {},
   "source": [
    "Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff57af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops duplicate entries\n",
    "\n",
    "print('num rows before dropping duplicates', len(new_data), len(y))\n",
    "new_data = new_data.drop_duplicates()\n",
    "new_labels = y.iloc[new_data.index]\n",
    "print('num ros after dropping duplicates', len(new_data), len(new_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dcc8e7",
   "metadata": {},
   "source": [
    "Now that we've identified major sources for leakage, we can safely split our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_from_seed(data: pd.DataFrame):\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train, test = train_test_split(\n",
    "        data,\n",
    "        test_size=0.2,\n",
    "        random_state=44\n",
    "    )\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train_X, test_X = split_from_seed(new_data)\n",
    "train_y, test_y = new_labels.loc[train_X.index], new_labels.loc[test_X.index]\n",
    "\n",
    "print(f'num samples in train: {len(train_X)}, should equal {len(train_y)}')\n",
    "print(f'num samples in train: {len(test_X)}, should equal {len(test_y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afbc4d3",
   "metadata": {},
   "source": [
    "Some columns will have missing values, in that case we can do one of a few things:\n",
    "1. Drop all rows with missing values\n",
    "2. Replace missing values\n",
    "\n",
    "To do this, we can use sklearn's ColumnTransformer, which will replace missing values with the mode (most common) feature."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
