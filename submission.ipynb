{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "t5RrQ1S6dgCu",
      "metadata": {
        "id": "t5RrQ1S6dgCu"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-01-29T15:17:52.522077Z",
          "start_time": "2026-01-29T15:17:49.226409Z"
        },
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# fetch dataset\n",
        "adult = fetch_ucirepo(id=2)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = adult.data.features\n",
        "y = adult.data.targets\n",
        "\n",
        "# metadata\n",
        "print(adult.metadata)\n",
        "\n",
        "# variable information\n",
        "print(adult.variables)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7d3f294",
      "metadata": {
        "id": "f7d3f294"
      },
      "source": [
        "## Dataset Analysis\n",
        "\n",
        "### About\n",
        "We chose the [Adult 2 dataset](https://archive.ics.uci.edu/dataset/2/adult) from UCI's Machine Learning Repository. This dataset compiles US Census information relevant to predicting income. It will be used to predict if a sample has an income over 50k USD a year.\n",
        "\n",
        "### Does it comply with the requirements?\n",
        "Adult 2 contains 48,000 rows, so it has over 2,000 rows. It contains 14 features, however some will not be used. We will still consider at least 10. Finally, there are several opportunities for encountering data leakage.\n",
        "\n",
        "First, a feature *fnl_wgt* computes how many rows in the dataset are like this. Frequency of a specific sample considers every sample in the set, which means this feature is not individual to the sample. Therefore, we will not consider this column during training.\n",
        "\n",
        "Second, there are several duplicate entries in the dataset. We must make each sample singular to give each sample equal weighting.\n",
        "\n",
        "Finally, there are two columns pertaining to education: a string representation and an enumeration of the string options. Both should not be used, as it may give that feature unequal weighting, and samples with unknown education backgrounds would be minimized.\n",
        "\n",
        "Therefore, this dataset is compliant with the project outlines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rBkBvaWXkLge",
      "metadata": {
        "id": "rBkBvaWXkLge"
      },
      "outputs": [],
      "source": [
        "# this block will drop some columns\n",
        "\n",
        "dropped_columns = [\n",
        "    'fnlwgt',\n",
        "    'education-num'\n",
        "]\n",
        "\n",
        "new_data = X.drop(columns=dropped_columns)\n",
        "\n",
        "print(new_data.columns)\n",
        "\n",
        "# now new_data has all the right variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3DS4pXBkWwu",
      "metadata": {
        "id": "c3DS4pXBkWwu"
      },
      "outputs": [],
      "source": [
        "# drops duplicate entries\n",
        "\n",
        "print(len(new_data))\n",
        "new_data = new_data.drop_duplicates()\n",
        "print(len(new_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdc6f7ea",
      "metadata": {
        "id": "bdc6f7ea"
      },
      "source": [
        "Some columns will have missing values, in that case we can do one of a few things:\n",
        "1. Drop all rows with missing values\n",
        "2. Replace missing values\n",
        "\n",
        "To do this, we can use sklearn's ColumnTransformer, which will replace missing values with the mode (most common) feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "459f0731634b658a",
      "metadata": {
        "id": "459f0731634b658a"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#80-20 random split\n",
        "rng = np.random.default_rng(0)\n",
        "idx = np.arange(len(X))\n",
        "rng.shuffle(idx)\n",
        "split = int(0.8 * len(idx))\n",
        "\n",
        "train_idx = idx[:split]\n",
        "test_idx  = idx[split:]\n",
        "\n",
        "X_train = X.iloc[train_idx]\n",
        "y_train = y.iloc[train_idx]\n",
        "\n",
        "X_test = X.iloc[test_idx]\n",
        "y_test = y.iloc[test_idx]\n",
        "\n",
        "num_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder())\n",
        "])\n",
        "\n",
        "num_cols = ['age', 'capital-gain', 'capital-loss']\n",
        "cat_cols = ['workclass', 'education', 'marital-status', 'occupation',\n",
        "            'relationship', 'race', 'sex', 'native-country']\n",
        "\n",
        "#Transform Data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', num_pipe, num_cols),  # Apply StandardScaler to numerical columns\n",
        "        ('cat', cat_pipe, cat_cols) # Apply OneHotEncoder to categorical columns\n",
        "    ],\n",
        "    remainder='passthrough' # Keep other columns\n",
        ")\n",
        "\n",
        "knn_pipe = Pipeline([\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"knn\", KNeighborsClassifier(n_neighbors=25, weights=\"distance\", p=1)),\n",
        "])\n",
        "\n",
        "knn_pipe.fit(X_train, y_train)\n",
        "pred = knn_pipe.predict(X_test)\n",
        "print(\"Test accuracy:\", accuracy_score(y_test, pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.13.11)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}